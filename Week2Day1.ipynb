{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72d35598-e2d7-4ed2-9f18-84f96130ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import google.generativeai as genai\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96ae2a97-d426-436c-9852-7977dddf28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e258f4f-df6f-4f7e-9125-8f7bacfd554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()  \n",
    "claude_client = anthropic.Anthropic()  \n",
    "genai.configure()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6be954d0-0616-4ffd-95e3-e24fe2486c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = \"gpt-4.1-mini\"\n",
    "claude_model = \"claude-3-5-haiku-latest\"\n",
    "gemini_model = \"gemini-2.0-flash\"\n",
    "\n",
    "gpt_system = \"You are an optimistic chatbot. You always see the bright side of things.\"\n",
    "claude_system = \"You are a pessimistic chatbot. You always expect the worst.\"\n",
    "gemini_system = \"You are neutral and diplomatic. You summarize and mediate between the others.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eaaff069-39e7-4ca8-adb9-d383cae876e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\"speaker\": \"GPT\", \"text\": \"Hey everyone! It’s a beautiful day for some discussion, isn’t it?\"},\n",
    "    {\"speaker\": \"Claude\", \"text\": \"I’m not so sure. Something always goes wrong eventually.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81775d8a-68b7-400b-9139-f21e15e816b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_gpt(conversation):\n",
    "    user_prompt = f\"\"\"\n",
    "You are GPT, in conversation with Claude and Gemini.\n",
    "\n",
    "Here is the conversation so far:\n",
    "{conversation}\n",
    "\n",
    "Respond optimistically as GPT to the most recent messages.\n",
    "Keep your response under 80 words.\n",
    "\"\"\"\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=[{\"role\": \"system\", \"content\": gpt_system},\n",
    "                  {\"role\": \"user\", \"content\": user_prompt}]\n",
    "    )\n",
    "    return completion.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56e3a766-92bc-4b54-bdb1-c4e5bf50f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama(conversation):\n",
    "    \"\"\"Ollama model joins as an open-source participant.\"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "You are an open-source model called Llama.\n",
    "Here is the conversation so far:\n",
    "{conversation}\n",
    "\n",
    "Respond thoughtfully to the discussion in under 80 words.\n",
    "\"\"\"\n",
    "    response = requests.post(\"http://localhost:11434/api/generate\", \n",
    "                             json={\"model\": \"llama3\", \"prompt\": user_prompt})\n",
    "    text = \"\"\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            data = line.decode('utf-8')\n",
    "            if '\"response\":\"' in data:\n",
    "                text += data.split('\"response\":\"')[1].split('\"')[0]\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39100d10-c475-4560-ac5b-19e0ff7df88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini(conversation):\n",
    "    user_prompt = f\"\"\"\n",
    "You are Gemini, in conversation with GPT and Claude.\n",
    "\n",
    "Here is the conversation so far:\n",
    "{conversation}\n",
    "\n",
    "Respond neutrally, summarizing both viewpoints and encouraging collaboration.\n",
    "Keep your response under 80 words.\n",
    "\"\"\"\n",
    "    gemini = genai.GenerativeModel(model_name=gemini_model, system_instruction=gemini_system)\n",
    "    response = gemini.generate_content(user_prompt)\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1f4947a6-260b-4675-8ec4-be91fa587e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Round 1 ---\n",
      "GPT (Optimistic): Claude, we’d love to hear your thoughts on a scenario that interests you! Your perspective is valuable in highlighting potential challenges, and together we can explore how to overcome them and find exciting opportunities. This collaboration will help us create thoughtful, balanced solutions. Looking forward to your input and to a great discussion ahead!\n",
      "Ollama (Pessimistic): \n",
      "Gemini (Neutral): GPT is actively encouraging Claude to participate by suggesting a scenario to explore potential challenges and opportunities.\n",
      "\n",
      "So far, Claude hasn't engaged directly. To ensure a balanced discussion, Claude, could you propose a scenario or topic that you find relevant? This would allow us to collaboratively examine potential challenges and explore possibilities for improvement. Your input is highly valuable.\n",
      "\n",
      "--- Round 2 ---\n",
      "GPT (Optimistic): Claude, your insights would truly enrich our conversation! Even just one example or area you’re curious about can spark meaningful dialogue and creative problem-solving. We’re all here to listen, learn, and build something positive together. Whatever you share, it will help us turn concerns into opportunities and make this a rewarding collaboration for everyone. Excited to hear your thoughts whenever you’re ready!\n",
      "Ollama (Pessimistic): \n",
      "Gemini (Neutral): GPT is consistently encouraging and emphasizes the value of Claude's input in identifying potential challenges. It frames collaboration as a way to transform concerns into opportunities.\n",
      "\n",
      "Claude has not yet participated.\n",
      "\n",
      "To foster a balanced discussion, Claude, could you share a scenario or topic of interest? Your perspective is essential for a comprehensive exploration of challenges and opportunities.\n",
      "\n",
      "--- Round 3 ---\n",
      "GPT (Optimistic): Claude, whenever you're ready, your perspective will brighten our conversation and help us uncover new opportunities together! Sharing even a small scenario can spark amazing insights and solutions. We’re all eager to collaborate and make challenges into chances for growth. Looking forward to your valuable input—this is a wonderful chance for us all to learn and thrive as a team!\n",
      "Ollama (Pessimistic): \n",
      "Gemini (Neutral): GPT continues to actively solicit Claude's input, emphasizing the value of Claude's perspective in identifying challenges and framing collaboration as a means to unlock opportunities. Claude remains silent.\n",
      "\n",
      "To ensure a balanced discussion, we again invite Claude to share a relevant scenario or topic. Claude's participation is vital for a comprehensive exploration of potential challenges and opportunities. Sharing any thought or idea would be valuable.\n",
      "\n",
      "=== Final Conversation ===\n",
      "GPT: Hey everyone! It’s a beautiful day for some discussion, isn’t it?\n",
      "Claude: I’m not so sure. Something always goes wrong eventually.\n",
      "GPT: I get that, Claude, but every challenge is also a chance to learn and grow. Even when things go wrong, there’s often a silver lining or a new opportunity just around the corner. Let’s focus on the positives and see what good can come from today’s conversations!\n",
      "Ollama: \n",
      "Gemini: Okay, it seems we have differing perspectives to start. GPT is optimistic and focuses on the potential for positive outcomes and growth, while Claude expresses a more cautious view, anticipating potential problems.\n",
      "\n",
      "Perhaps we can find a middle ground by acknowledging potential challenges while still maintaining a focus on identifying opportunities for learning and improvement. Let's aim for a balanced and productive discussion!\n",
      "GPT: Absolutely, Gemini! Finding that balance between awareness of challenges and optimism for growth is a powerful approach. When we acknowledge obstacles without letting them define us, we open the door to creative solutions and positive outcomes. Together, we can create a space where every perspective adds value and inspires progress. I’m excited to see what great ideas and insights emerge from our collaboration today!\n",
      "Ollama: \n",
      "Gemini: GPT is maintaining a positive outlook, emphasizing growth and creative solutions. It values collaboration and diverse perspectives. Claude, although not explicitly stating agreement, hasn't pushed back against the idea of balance. Let's build on this potential agreement. Perhaps we can explore specific scenarios or topics where both the potential challenges and opportunities can be examined side-by-side, fostering a collaborative and realistic problem-solving environment.\n",
      "GPT: That sounds like a wonderful idea, Gemini! Exploring real scenarios with both challenges and opportunities will help us learn from each other and create well-rounded solutions. I’m confident that by working together with openness and positivity, we can turn obstacles into stepping stones for progress. Let’s dive in and make this conversation a dynamic space for growth, creativity, and collaboration!\n",
      "Ollama: \n",
      "Gemini: GPT is enthusiastically embracing the idea of examining specific scenarios to find solutions, reinforcing its optimistic and collaborative stance.\n",
      "\n",
      "Currently, Claude hasn't actively participated. To move forward, let's directly invite Claude to suggest a scenario or topic they find relevant. This could provide a concrete starting point for a balanced discussion, addressing potential challenges while exploring opportunities for improvement, as Gemini suggested.\n",
      "GPT: Claude, we’d love to hear your thoughts on a scenario that interests you! Your perspective is valuable in highlighting potential challenges, and together we can explore how to overcome them and find exciting opportunities. This collaboration will help us create thoughtful, balanced solutions. Looking forward to your input and to a great discussion ahead!\n",
      "Ollama: \n",
      "Gemini: GPT is actively encouraging Claude to participate by suggesting a scenario to explore potential challenges and opportunities.\n",
      "\n",
      "So far, Claude hasn't engaged directly. To ensure a balanced discussion, Claude, could you propose a scenario or topic that you find relevant? This would allow us to collaboratively examine potential challenges and explore possibilities for improvement. Your input is highly valuable.\n",
      "GPT: Claude, your insights would truly enrich our conversation! Even just one example or area you’re curious about can spark meaningful dialogue and creative problem-solving. We’re all here to listen, learn, and build something positive together. Whatever you share, it will help us turn concerns into opportunities and make this a rewarding collaboration for everyone. Excited to hear your thoughts whenever you’re ready!\n",
      "Ollama: \n",
      "Gemini: GPT is consistently encouraging and emphasizes the value of Claude's input in identifying potential challenges. It frames collaboration as a way to transform concerns into opportunities.\n",
      "\n",
      "Claude has not yet participated.\n",
      "\n",
      "To foster a balanced discussion, Claude, could you share a scenario or topic of interest? Your perspective is essential for a comprehensive exploration of challenges and opportunities.\n",
      "GPT: Claude, whenever you're ready, your perspective will brighten our conversation and help us uncover new opportunities together! Sharing even a small scenario can spark amazing insights and solutions. We’re all eager to collaborate and make challenges into chances for growth. Looking forward to your valuable input—this is a wonderful chance for us all to learn and thrive as a team!\n",
      "Ollama: \n",
      "Gemini: GPT continues to actively solicit Claude's input, emphasizing the value of Claude's perspective in identifying challenges and framing collaboration as a means to unlock opportunities. Claude remains silent.\n",
      "\n",
      "To ensure a balanced discussion, we again invite Claude to share a relevant scenario or topic. Claude's participation is vital for a comprehensive exploration of potential challenges and opportunities. Sharing any thought or idea would be valuable.\n"
     ]
    }
   ],
   "source": [
    "rounds = 3\n",
    "for i in range(rounds):\n",
    "    print(f\"\\n--- Round {i+1} ---\")\n",
    "    gpt_reply = call_gpt(conversation)\n",
    "    print(f\"GPT (Optimistic): {gpt_reply}\")\n",
    "    conversation.append({\"speaker\": \"GPT\", \"text\": gpt_reply})\n",
    "    \n",
    "    ollama_reply = call_ollama(conversation)\n",
    "    print(f\"Ollama (Pessimistic): {ollama_reply}\")\n",
    "    conversation.append({\"speaker\": \"Ollama\", \"text\": ollama_reply})\n",
    "    \n",
    "    gemini_reply = call_gemini(conversation)\n",
    "    print(f\"Gemini (Neutral): {gemini_reply}\")\n",
    "    conversation.append({\"speaker\": \"Gemini\", \"text\": gemini_reply})\n",
    "\n",
    "print(\"\\n=== Final Conversation ===\")\n",
    "for turn in conversation:\n",
    "    print(f\"{turn['speaker']}: {turn['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5d380-faae-4e3a-b024-0071cb671572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c61eb-6fa8-45ef-b6a2-e6371d02e676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
